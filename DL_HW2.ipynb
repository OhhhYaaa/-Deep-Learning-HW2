{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1c2a45-718a-4ccf-8a22-e6e6d4959cc8",
   "metadata": {},
   "source": [
    "# DL_HW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f85e11-365b-4241-b517-a6db3aa19bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(120000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, os, pickle, json, random\n",
    "\n",
    "from imageio import imread, imwrite\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, trange\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from skimage import feature, data, color\n",
    "import skimage\n",
    "import cv2\n",
    "from functools import partial\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "cpus = multiprocessing.cpu_count()\n",
    "print(cpus)\n",
    "%autosave 120"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00099a9-58d5-4ccc-9117-e5ca5e3e6770",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tool Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38d204e-dd07-4af3-ad8e-5cc9dc9788ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot\n",
    "def self_onehot(x, c = 50) : \n",
    "    x_onehot = np.zeros([x.shape[0], c])\n",
    "    for i in range(x.shape[0]) :\n",
    "        x_onehot[i, int(x[i])] = 1\n",
    "    return x_onehot\n",
    "\n",
    "# 讀取圖片function\n",
    "def read_img(path) :\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (256, 256))\n",
    "    return img\n",
    "\n",
    "# color histogram\n",
    "def color_histogram(img, hist_size = 256):\n",
    "    img = img.astype(np.uint8)\n",
    "    color = ('b','g','r')\n",
    "    histogram = []\n",
    "    for idx, color in enumerate(color):\n",
    "        h = cv2.calcHist(img,[idx],None,[hist_size],[0, 256])\n",
    "        histogram.append(h)\n",
    "    return np.array(histogram).squeeze().reshape(1, -1)\n",
    "# histogram of gradient\n",
    "def get_hog_feature(img) :\n",
    "    img = img.astype(np.uint8)\n",
    "    hog_vec, hog_vis = feature.hog(img, \n",
    "                               pixels_per_cell=(64, 64), \n",
    "                               cells_per_block = [1, 1],\n",
    "                               channel_axis = 2, \n",
    "                               visualize=True)\n",
    "    return hog_vec\n",
    "\n",
    "# haralick\n",
    "def get_haralick(img): \n",
    "    values_temp = []\n",
    "    img = img.astype(np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    glcm = skimage.feature.graycomatrix(img, [2, 8, 16], [0, np.pi / 4, np.pi / 2, np.pi * 3 / 4], 256, symmetric=True, normed=True)  # , np.pi / 4, np.pi / 2, np.pi * 3 / 4\n",
    "    # print(glcm.shape) \n",
    "    for prop in {'contrast', 'dissimilarity','homogeneity', 'energy', 'correlation', 'ASM'}:\n",
    "        temp = skimage.feature.graycoprops(glcm, prop)\n",
    "        temp = np.array(temp).reshape(-1)\n",
    "        values_temp.append(temp)\n",
    "        # print(prop, temp)\n",
    "        # print('len:',len(temp))\n",
    "        # print('')\n",
    "    values_temp = np.array(values_temp).reshape(1, -1)\n",
    "    return (values_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f07b363-6f3a-4754-9baa-98d30a8faf28",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read Data and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc5de90-93f9-40ce-b751-87b0918c61f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取index\n",
    "os.chdir('/home/rita/111/111-2DL/HW1')\n",
    "train_idx = pd.read_table('train.txt', header = None, sep = ' ')\n",
    "val_idx = pd.read_table('val.txt', header = None, sep = ' ')\n",
    "test_idx = pd.read_table('test.txt', header = None, delimiter = ' ')\n",
    "train_idx = np.array(train_idx)\n",
    "val_idx = np.array(val_idx)\n",
    "test_idx = np.array(test_idx)\n",
    "train_y = train_idx[::, 1].astype(float)\n",
    "val_y = val_idx[::, 1].astype(float)\n",
    "test_y = test_idx[::, 1].astype(float)\n",
    "os.chdir('/home/rita/111/111-2DL/HW2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86ba40ec-20d9-483f-9653-c9a27fd6630f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63325/63325 [00:37<00:00, 1691.92it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 729.29it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 647.93it/s]\n",
      "100%|██████████| 63325/63325 [00:33<00:00, 1892.40it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 2509.86it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 2739.26it/s]\n",
      "100%|██████████| 63325/63325 [00:56<00:00, 1120.87it/s]\n",
      "100%|██████████| 450/450 [00:01<00:00, 237.06it/s]\n",
      "100%|██████████| 450/450 [00:01<00:00, 236.97it/s]\n",
      "100%|██████████| 63325/63325 [02:40<00:00, 394.01it/s]\n",
      "100%|██████████| 450/450 [00:07<00:00, 57.18it/s]\n",
      "100%|██████████| 450/450 [00:07<00:00, 56.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348.76488161087036\n"
     ]
    }
   ],
   "source": [
    "# 讀取圖片\n",
    "# 40 s\n",
    "os.chdir('/home/rita/111/111-2DL/HW1')\n",
    "s = time.time()\n",
    "if __name__ == '__main__' : \n",
    "    with Pool(processes = 80) as p:\n",
    "        train_pic = list(tqdm(p.imap(read_img, train_idx[::, 0], chunksize=100), total = train_idx.shape[0]))\n",
    "        val_pic = list(tqdm(p.imap(read_img, val_idx[::, 0], chunksize=100), total = val_idx.shape[0]))\n",
    "        test_pic = list(tqdm(p.imap(read_img, test_idx[::, 0], chunksize=100), total = test_idx.shape[0]))\n",
    "os.chdir('/home/rita/111/111-2DL/HW2')\n",
    "\n",
    "train_pic_list = train_pic\n",
    "val_pic_list = val_pic\n",
    "test_pic_list = test_pic\n",
    "\n",
    "train_pic = np.array(train_pic)\n",
    "val_pic = np.array(val_pic)\n",
    "test_pic = np.array(test_pic)\n",
    "\n",
    "np.save('./data/train_pic', train_pic)\n",
    "np.save('./data/val_pic', val_pic)\n",
    "np.save('./data/test_pic', test_pic)\n",
    "\n",
    "func = partial(color_histogram, hist_size = 64)\n",
    "with Pool(processes = 40) as p:\n",
    "    train_x_color_hist = list(tqdm(p.imap(func, train_pic_list, chunksize=1000), total = train_idx.shape[0]))\n",
    "    val_x_color_hist = list(tqdm(p.imap(func, val_pic_list, chunksize=100), total = val_idx.shape[0]))\n",
    "    test_x_color_hist = list(tqdm(p.imap(func, test_pic_list, chunksize=100), total = test_idx.shape[0]))\n",
    "train_x_color_hist = np.array(train_x_color_hist).squeeze()\n",
    "val_x_color_hist = np.array(val_x_color_hist).squeeze()\n",
    "test_x_color_hist = np.array(test_x_color_hist).squeeze()\n",
    "\n",
    "with Pool(processes = 40) as p:\n",
    "    train_x_hog = list(tqdm(p.imap(get_hog_feature, train_pic_list, chunksize=100), total = train_idx.shape[0]))\n",
    "    val_x_hog = list(tqdm(p.imap(get_hog_feature, val_pic_list, chunksize=100), total = val_idx.shape[0]))\n",
    "    test_x_hog = list(tqdm(p.imap(get_hog_feature, test_pic_list, chunksize=100), total = test_idx.shape[0])) \n",
    "train_x_hog = np.array(train_x_hog)\n",
    "val_x_hog = np.array(val_x_hog)\n",
    "test_x_hog = np.array(test_x_hog)\n",
    "\n",
    "with Pool(40) as p:\n",
    "    train_x_haralick = list(tqdm(p.imap(get_haralick, train_pic_list, chunksize=100), total = train_idx.shape[0]))\n",
    "    val_x_haralick = list(tqdm(p.imap(get_haralick, val_pic_list, chunksize=100), total = val_idx.shape[0]))\n",
    "    test_x_haralick = list(tqdm(p.imap(get_haralick, test_pic_list, chunksize=100), total = test_idx.shape[0])) \n",
    "train_x_haralick = np.array(train_x_haralick).squeeze()\n",
    "val_x_haralick = np.array(val_x_haralick).squeeze()\n",
    "test_x_haralick = np.array(test_x_haralick).squeeze()\n",
    "\n",
    "train_x = np.concatenate([train_x_color_hist, train_x_hog, train_x_haralick], axis = 1)\n",
    "val_x = np.concatenate([val_x_color_hist, val_x_hog, val_x_haralick], axis = 1)\n",
    "test_x = np.concatenate([test_x_color_hist, test_x_hog, test_x_haralick], axis = 1)\n",
    "\n",
    "np.save('./data/train_x', train_x)\n",
    "np.save('./data/val_x', val_x)\n",
    "np.save('./data/test_x', test_x)\n",
    "print(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a1c241-df86-4939-9165-277a334cf521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取index\n",
    "os.chdir('/home/rita/111/111-2DL/HW1')\n",
    "train_idx = pd.read_table('train.txt', header = None, sep = ' ')\n",
    "val_idx = pd.read_table('val.txt', header = None, sep = ' ')\n",
    "test_idx = pd.read_table('test.txt', header = None, delimiter = ' ')\n",
    "train_idx = np.array(train_idx)\n",
    "val_idx = np.array(val_idx)\n",
    "test_idx = np.array(test_idx)\n",
    "train_y = train_idx[::, 1].astype(float)\n",
    "val_y = val_idx[::, 1].astype(float)\n",
    "test_y = test_idx[::, 1].astype(float)\n",
    "os.chdir('/home/rita/111/111-2DL/HW2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aae968c-ec8d-4d67-bab2-252fd98aa2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_onehot = self_onehot(train_y)\n",
    "val_y_onehot = self_onehot(val_y)\n",
    "test_y_onehot = self_onehot(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d303ccc5-6121-4193-98e5-72c8b19e11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pic = np.load('./data/train_pic.npy')\n",
    "val_pic = np.load('./data/val_pic.npy')\n",
    "test_pic = np.load('./data/test_pic.npy')\n",
    "train_x = np.load('./data/train_x.npy')\n",
    "val_x = np.load('./data/val_x.npy')\n",
    "test_x = np.load('./data/test_x.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec61ec8-e8b4-48e9-aa4e-d502110a8931",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23aee710-c833-40e7-a420-2a454acd04f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_DataLoader() :\n",
    "    def __init__(self, data, label, batch_size = 64, shuffle = False) :\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_sample = data.shape[0]\n",
    "        self.n_batches = (self.n_sample // self.batch_size) # + 1\n",
    "        self.start = 0\n",
    "        self.end = self.start + self.batch_size\n",
    "        if self.shuffle : np.random.shuffle(np.arange(self.n_sample))\n",
    "                \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "        \n",
    "    def __next__(self):\n",
    "        if self.end >= self.n_sample :\n",
    "            self.start = 0\n",
    "            self.end = self.start + self.batch_size\n",
    "            if self.shuffle : np.random.shuffle(np.arange(self.n_sample))\n",
    "            raise StopIteration\n",
    "        datas = self.data[self.start : self.end]\n",
    "        labels = self.label[self.start : self.end]\n",
    "        \n",
    "        self.start += self.batch_size\n",
    "        self.end += self.batch_size\n",
    "        return datas, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "689f0fde-4a38-4a09-999e-337c2923a0f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class self_MLP() :\n",
    "    def __init__(self, n_input, n_output, n_hidden, n_epochs, learning_rate) :\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_epochs = n_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        # he initialization  \n",
    "        self.w1 = np.random.randn(self.n_input, self.n_hidden) * np.sqrt(2 / self.n_input)\n",
    "        self.b1 = np.zeros((1, self.n_hidden))\n",
    "        self.w2 = np.random.randn(self.n_hidden, self.n_output) * np.sqrt(2 / self.n_hidden)\n",
    "        self.b2 = np.zeros((1, self.n_output))\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        # nf * fh + 1h = nh\n",
    "        self.z1 = np.dot(x, self.w1) + self.b1 \n",
    "        self.a1 = self.softmax(self.z1)           \n",
    "        # nh * ho + 1o = no\n",
    "        self.z2 = np.dot(self.a1, self.w2) + self.b2 \n",
    "        self.y_hat = self.softmax(self.z2)            # y\n",
    "        # no\n",
    "        return self.y_hat\n",
    "        \n",
    "    def backward(self, x, y) :\n",
    "        # no\n",
    "        dy = self.y_hat - y\n",
    "        # ho = hn * no\n",
    "        dw2 = np.dot(self.a1.T, dy)\n",
    "        # 1o = no.sum\n",
    "        db2 = np.sum(dy, axis = 0, keepdims = True)\n",
    "        # nh = no * oh \n",
    "        ds = np.dot(dy, self.w2.T) * self.a1 * (1 - self.a1)\n",
    "        # fh = fn *    nh\n",
    "        dw1 = np.dot(np.transpose(x), ds)\n",
    "        # 1h = nh.sum\n",
    "        db1 = np.sum(ds, axis=0, keepdims=True)\n",
    "        \n",
    "        self.w1 -= self.learning_rate * dw1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "        self.w2 -= self.learning_rate * dw2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "        \n",
    "    def loss_fn(self, y_hat, y) :\n",
    "        n = y.shape[0]\n",
    "        temp = np.mean(-np.sum(y * np.log(y_hat), axis = 1))\n",
    "        return temp\n",
    "        # return temp.squeeze()\n",
    "        \n",
    "    def softmax(self, x) :\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims = True)\n",
    "    \n",
    "    def train(self, dataloader) : \n",
    "        ls_loss = []\n",
    "        \n",
    "        for epoch in trange(1, n_epochs + 1) :\n",
    "\n",
    "            for x, y in dataloader : \n",
    "                y_hat = self.forward(x)\n",
    "                loss = self.loss_fn(y_hat, y)\n",
    "                self.backward(x, y)\n",
    "            # if(epoch % 1 == 0) : print('Epochs : ', epoch, ' Loss : ', loss)\n",
    "            ls_loss.append(loss)\n",
    "        return ls_loss\n",
    "    \n",
    "    def predict(self, x) :\n",
    "        y_hat = self.forward(x)\n",
    "        # return y_hat\n",
    "        return np.argmax(y_hat, axis = 1)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34a4925d-5070-4fb6-9a74-6dff521e8575",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:51<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "n_input = train_x.shape[1]\n",
    "n_output = 50\n",
    "n_hidden = 128\n",
    "n_epochs = 200\n",
    "learning_rate = 1e-4\n",
    "model = self_MLP(\n",
    "    n_input = n_input, \n",
    "    n_output = n_output, \n",
    "    n_hidden = n_hidden, \n",
    "    n_epochs = n_epochs, \n",
    "    learning_rate = learning_rate\n",
    ")\n",
    "trainx = preprocessing.scale(train_x)\n",
    "train_dataloader = Self_DataLoader(trainx, train_y_onehot, batch_size = 128, shuffle=True)\n",
    "ls_loss = model.train(train_dataloader)\n",
    "\n",
    "filename = './model/TwoLayerPerceptron.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "with open(\"loss.txt\", \"w\") as fp:\n",
    "    json.dump(ls_loss, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52d1ea27-4b23-4e3b-8548-084c02f37eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = './model/TwoLayerPerceptron.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "with open(\"loss.txt\", \"r\") as fp:\n",
    "    ls_loss = json.load(fp)\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.title('Loss')\n",
    "temp = np.array(ls_loss)\n",
    "plt.plot(range(len(ls_loss)), temp)\n",
    "# plt.savefig('./figure/loss.png')\n",
    "# plt.close(fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a645a1-50fc-4899-94a4-6f288a5eb367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.05768653770232925\n",
      "val Accuracy :  0.05333333333333334\n",
      "Test Accuracy :  0.05555555555555555\n"
     ]
    }
   ],
   "source": [
    "trainx = preprocessing.scale(train_x)\n",
    "pred_y = loaded_model.predict(trainx)\n",
    "acc = np.mean(pred_y == train_y)\n",
    "print('Train Accuracy : ', acc)\n",
    "valx = preprocessing.scale(val_x)\n",
    "pred_y = loaded_model.predict(valx)\n",
    "acc = np.mean(pred_y == val_y)\n",
    "print('val Accuracy : ', acc)\n",
    "testx = preprocessing.scale(test_x)\n",
    "pred_y = loaded_model.predict(testx)\n",
    "acc = np.mean(pred_y == test_y)\n",
    "print('Test Accuracy : ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd647907-2210-4ef4-8180-7ce3982f8d74",
   "metadata": {},
   "source": [
    "### Compare with sklearn Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f51836a-c059-430a-9ec5-be158be5af92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集:  0.05009080142123964\n",
      "驗證集:  0.051111111111111114\n",
      "測試集:  0.044444444444444446\n"
     ]
    }
   ],
   "source": [
    "clf = Perceptron(tol=1e-5, n_jobs = 40, early_stopping = True, warm_start = True, max_iter = 2000)\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "print('訓練集: ', clf.score(train_x, train_y))\n",
    "print('驗證集: ', clf.score(val_x, val_y))\n",
    "print('測試集: ', clf.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca537f-7b0c-4b0e-b659-b85618d932b7",
   "metadata": {},
   "source": [
    "## Lenet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67b8460d-11d9-4705-9c15-8bfc7b513aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reference : https://github.com/toxtli/lenet-5-mnist-from-scratch-numpy/blob/master/app.py\n",
    "\n",
    "# def MakeOneHot(Y, D_out):\n",
    "#     N = Y.shape[0]\n",
    "#     Z = np.zeros((N, D_out))\n",
    "#     Z[np.arange(N), Y] = 1\n",
    "#     return Z\n",
    "\n",
    "\n",
    "\n",
    "def draw_losses(losses):\n",
    "    t = np.arange(len(losses))\n",
    "    plt.plot(t, losses)\n",
    "    plt.show()\n",
    "\n",
    "def get_batch(X, Y, batch_size):\n",
    "    N = len(X)\n",
    "    i = random.randint(1, N-batch_size)\n",
    "    return X[i:i+batch_size], Y[i:i+batch_size]\n",
    "\n",
    "class FC():\n",
    "    def __init__(self, D_in, D_out):\n",
    "        self.cache = None\n",
    "        self.W = {'val': np.random.normal(0.0, np.sqrt(2/D_in), (D_in,D_out)), 'grad': 0}\n",
    "        self.b = {'val': np.random.randn(D_out), 'grad': 0}\n",
    "\n",
    "    def _forward(self, X):\n",
    "        out = np.dot(X, self.W['val']) + self.b['val']\n",
    "        self.cache = X\n",
    "        return out\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        X = self.cache\n",
    "        dX = np.dot(dout, self.W['val'].T).reshape(X.shape)\n",
    "        self.W['grad'] = np.dot(X.reshape(X.shape[0], np.prod(X.shape[1:])).T, dout)\n",
    "        self.b['grad'] = np.sum(dout, axis=0)\n",
    "        #self._update_params()\n",
    "        return dX\n",
    "\n",
    "    def _update_params(self, lr=0.001):\n",
    "        # Update the parameters\n",
    "        self.W['val'] -= lr*self.W['grad']\n",
    "        self.b['val'] -= lr*self.b['grad']\n",
    "\n",
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        out = np.maximum(0, X)\n",
    "        self.cache = X\n",
    "        return out\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        X = self.cache\n",
    "        dX = np.array(dout, copy=True)\n",
    "        dX[X <= 0] = 0\n",
    "        return dX\n",
    "\n",
    "class Softmax():\n",
    "    \"\"\"\n",
    "    Softmax activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        #print(\"Build Softmax\")\n",
    "        self.cache = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        #print(\"Softmax: _forward\")\n",
    "        maxes = np.amax(X, axis=1)\n",
    "        maxes = maxes.reshape(maxes.shape[0], 1)\n",
    "        Y = np.exp(X - maxes)\n",
    "        Z = Y / np.sum(Y, axis=1).reshape(Y.shape[0], 1)\n",
    "        self.cache = (X, Y, Z)\n",
    "        return Z # distribution\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        X, Y, Z = self.cache\n",
    "        dZ = np.zeros(X.shape)\n",
    "        dY = np.zeros(X.shape)\n",
    "        dX = np.zeros(X.shape)\n",
    "        N = X.shape[0]\n",
    "        for n in range(N):\n",
    "            i = np.argmax(Z[n])\n",
    "            dZ[n,:] = np.diag(Z[n]) - np.outer(Z[n],Z[n])\n",
    "            M = np.zeros((N,N))\n",
    "            M[:,i] = 1\n",
    "            dY[n,:] = np.eye(N) - M\n",
    "        dX = np.dot(dout,dZ)\n",
    "        dX = np.dot(dX,dY)\n",
    "        return dX\n",
    "    \n",
    "    \n",
    "class Conv():\n",
    "    def __init__(self, Cin, Cout, F, stride=1, padding=0, bias=True):\n",
    "        self.Cin = Cin\n",
    "        self.Cout = Cout\n",
    "        self.F = F\n",
    "        self.S = stride\n",
    "        self.W = {'val': np.random.normal(0.0,np.sqrt(2/Cin),(Cout,Cin,F,F)), 'grad': 0} # Xavier Initialization\n",
    "        self.b = {'val': np.random.randn(Cout), 'grad': 0}\n",
    "        self.cache = None\n",
    "        self.pad = padding\n",
    "\n",
    "    def _forward(self, X):\n",
    "        X = np.pad(X, ((0,0),(0,0),(self.pad,self.pad),(self.pad,self.pad)), 'constant')\n",
    "        (N, Cin, H, W) = X.shape\n",
    "        H_ = H - self.F + 1\n",
    "        W_ = W - self.F + 1\n",
    "        Y = np.zeros((N, self.Cout, H_, W_))\n",
    "\n",
    "        for n in range(N):\n",
    "            for c in range(self.Cout):\n",
    "                for h in range(H_):\n",
    "                    for w in range(W_):\n",
    "                        Y[n, c, h, w] = np.sum(X[n, :, h:h+self.F, w:w+self.F] * self.W['val'][c, :, :, :]) + self.b['val'][c]\n",
    "\n",
    "        self.cache = X\n",
    "        return Y\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        # dout (N,Cout,H_,W_)\n",
    "        # W (Cout, Cin, F, F)\n",
    "        X = self.cache\n",
    "        (N, Cin, H, W) = X.shape\n",
    "        H_ = H - self.F + 1\n",
    "        W_ = W - self.F + 1\n",
    "        W_rot = np.rot90(np.rot90(self.W['val']))\n",
    "\n",
    "        dX = np.zeros(X.shape)\n",
    "        dW = np.zeros(self.W['val'].shape)\n",
    "        db = np.zeros(self.b['val'].shape)\n",
    "\n",
    "        # dW\n",
    "        for co in range(self.Cout):\n",
    "            for ci in range(Cin):\n",
    "                for h in range(self.F):\n",
    "                    for w in range(self.F):\n",
    "                        dW[co, ci, h, w] = np.sum(X[:,ci,h:h+H_,w:w+W_] * dout[:,co,:,:])\n",
    "\n",
    "        # db\n",
    "        for co in range(self.Cout):\n",
    "            db[co] = np.sum(dout[:,co,:,:])\n",
    "\n",
    "        dout_pad = np.pad(dout, ((0,0),(0,0),(self.F,self.F),(self.F,self.F)), 'constant')\n",
    "        #print(\"dout_pad.shape: \" + str(dout_pad.shape))\n",
    "        # dX\n",
    "        for n in range(N):\n",
    "            for ci in range(Cin):\n",
    "                for h in range(H):\n",
    "                    for w in range(W):\n",
    "                        #print(\"self.F.shape: %s\", self.F)\n",
    "                        #print(\"%s, W_rot[:,ci,:,:].shape: %s, dout_pad[n,:,h:h+self.F,w:w+self.F].shape: %s\" % ((n,ci,h,w),W_rot[:,ci,:,:].shape, dout_pad[n,:,h:h+self.F,w:w+self.F].shape))\n",
    "                        dX[n, ci, h, w] = np.sum(W_rot[:,ci,:,:] * dout_pad[n, :, h:h+self.F,w:w+self.F])\n",
    "\n",
    "        return dX\n",
    "\n",
    "class MaxPool():\n",
    "    def __init__(self, F, stride):\n",
    "        self.F = F\n",
    "        self.S = stride\n",
    "        self.cache = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        # X: (N, Cin, H, W): maxpool along 3rd, 4th dim\n",
    "        (N,Cin,H,W) = X.shape\n",
    "        F = self.F\n",
    "        W_ = int(float(W)/F)\n",
    "        H_ = int(float(H)/F)\n",
    "        Y = np.zeros((N,Cin,W_,H_))\n",
    "        M = np.zeros(X.shape) # mask\n",
    "        for n in range(N):\n",
    "            for cin in range(Cin):\n",
    "                for w_ in range(W_):\n",
    "                    for h_ in range(H_):\n",
    "                        Y[n,cin,w_,h_] = np.max(X[n,cin,F*w_:F*(w_+1),F*h_:F*(h_+1)])\n",
    "                        i,j = np.unravel_index(X[n,cin,F*w_:F*(w_+1),F*h_:F*(h_+1)].argmax(), (F,F))\n",
    "                        M[n,cin,F*w_+i,F*h_+j] = 1\n",
    "        self.cache = M\n",
    "        return Y\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        M = self.cache\n",
    "        (N,Cin,H,W) = M.shape\n",
    "        dout = np.array(dout)\n",
    "        #print(\"dout.shape: %s, M.shape: %s\" % (dout.shape, M.shape))\n",
    "        dX = np.zeros(M.shape)\n",
    "        for n in range(N):\n",
    "            for c in range(Cin):\n",
    "                #print(\"(n,c): (%s,%s)\" % (n,c))\n",
    "                dX[n,c,:,:] = dout[n,c,:,:].repeat(2, axis=0).repeat(2, axis=1)\n",
    "        return dX*M\n",
    "\n",
    "def NLLLoss(Y_pred, Y_true):\n",
    "    \"\"\"\n",
    "    Negative log likelihood loss\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    N = Y_pred.shape[0]\n",
    "    M = np.sum(Y_pred*Y_true, axis=1)\n",
    "    for e in M:\n",
    "        #print(e)\n",
    "        if e == 0:\n",
    "            loss += 500\n",
    "        else:\n",
    "            loss += -np.log(e)\n",
    "    return loss/N\n",
    "    \n",
    "class CrossEntropyLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get(self, Y_pred, Y_true):\n",
    "        N = Y_pred.shape[0]\n",
    "        softmax = Softmax()\n",
    "        prob = softmax._forward(Y_pred)\n",
    "        loss = NLLLoss(prob, Y_true)\n",
    "        Y_serial = np.argmax(Y_true, axis=1)\n",
    "        dout = prob.copy()\n",
    "        dout[np.arange(N), Y_serial] -= 1\n",
    "        return loss, dout\n",
    "\n",
    "class Net(metaclass=ABCMeta):\n",
    "    # Neural network super class\n",
    "\n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, X):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def backward(self, dout):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_params(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_params(self, params):\n",
    "        pass\n",
    "\n",
    "class SGD():\n",
    "    def __init__(self, params, lr=0.001, reg=0):\n",
    "        self.parameters = params\n",
    "        self.lr = lr\n",
    "        self.reg = reg\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.parameters:\n",
    "            param['val'] -= (self.lr*param['grad'] + self.reg*param['val'])\n",
    "    \n",
    "class SGDMomentum():\n",
    "    def __init__(self, params, lr=0.001, momentum=0.99, reg=0):\n",
    "        self.l = len(params)\n",
    "        self.parameters = params\n",
    "        self.velocities = []\n",
    "        for param in self.parameters:\n",
    "            self.velocities.append(np.zeros(param['val'].shape))\n",
    "        self.lr = lr\n",
    "        self.rho = momentum\n",
    "        self.reg = reg\n",
    "\n",
    "    def step(self):\n",
    "        for i in range(self.l):\n",
    "            self.velocities[i] = self.rho*self.velocities[i] + (1-self.rho)*self.parameters[i]['grad']\n",
    "            self.parameters[i]['val'] -= (self.lr*self.velocities[i] + self.reg*self.parameters[i]['val'])\n",
    "\n",
    "def softmax(self, x) :\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims = True)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd0b97-ac32-49f3-bedc-8070c208e576",
   "metadata": {},
   "source": [
    "### test for mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "513c9d72-1cf4-484b-8b3d-410eb305c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(Net):\n",
    "    # LeNet5\n",
    "\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv(1, 6, 5) # C1(1*32*32 --> 6*28*28)\n",
    "        self.ReLU1 = ReLU()\n",
    "        self.pool1 = MaxPool(2,2) # S2(6*28*28  --> 6*14*14)\n",
    "        self.conv2 = Conv(6, 16, 5) # C3(6*14*14 --> 16*10*10)\n",
    "        self.ReLU2 = ReLU()\n",
    "        self.pool2 = MaxPool(2,2) # S4(16*5*5)\n",
    "        self.FC1 = FC(16*4*4, 120) # C5()\n",
    "        self.ReLU3 = ReLU()\n",
    "        self.FC2 = FC(120, 84) # F6\n",
    "        self.ReLU4 = ReLU()\n",
    "        self.FC3 = FC(84, 10)\n",
    "        self.Softmax = Softmax()\n",
    "\n",
    "        self.p2_shape = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        h1 = self.conv1._forward(X)\n",
    "        a1 = self.ReLU1._forward(h1)\n",
    "        p1 = self.pool1._forward(a1)\n",
    "        h2 = self.conv2._forward(p1)\n",
    "        a2 = self.ReLU2._forward(h2)\n",
    "        p2 = self.pool2._forward(a2)\n",
    "        self.p2_shape = p2.shape\n",
    "        fl = p2.reshape(X.shape[0],-1) # Flatten\n",
    "        h3 = self.FC1._forward(fl)\n",
    "        a3 = self.ReLU3._forward(h3)\n",
    "        h4 = self.FC2._forward(a3)\n",
    "        a5 = self.ReLU4._forward(h4)\n",
    "        h5 = self.FC3._forward(a5)\n",
    "        a5 = self.Softmax._forward(h5)\n",
    "        return a5\n",
    "\n",
    "    def backward(self, dout):\n",
    "        #dout = self.Softmax._backward(dout)\n",
    "        dout = self.FC3._backward(dout)\n",
    "        dout = self.ReLU4._backward(dout)\n",
    "        dout = self.FC2._backward(dout)\n",
    "        dout = self.ReLU3._backward(dout)\n",
    "        dout = self.FC1._backward(dout)\n",
    "        dout = dout.reshape(self.p2_shape) # reshape\n",
    "        dout = self.pool2._backward(dout)\n",
    "        dout = self.ReLU2._backward(dout)\n",
    "        dout = self.conv2._backward(dout)\n",
    "        dout = self.pool1._backward(dout)\n",
    "        dout = self.ReLU1._backward(dout)\n",
    "        dout = self.conv1._backward(dout)\n",
    "\n",
    "    def get_params(self):\n",
    "        return [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b]\n",
    "\n",
    "    def set_params(self, params):\n",
    "        [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d691fbba-f47e-418e-88fc-ccfa9f317b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = [\n",
    "\t[\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
    "\t[\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
    "\t[\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
    "\t[\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
    "]\n",
    "\n",
    "def download_mnist():\n",
    "    base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "    for name in filename:\n",
    "        print(\"Downloading \"+name[1]+\"...\")\n",
    "        request.urlretrieve(base_url+name[1], name[1])\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "def save_mnist():\n",
    "    mnist = {}\n",
    "    for name in filename[:2]:\n",
    "        with gzip.open(name[1], 'rb') as f:\n",
    "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
    "    for name in filename[-2:]:\n",
    "        with gzip.open(name[1], 'rb') as f:\n",
    "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    with open(\"mnist.pkl\", 'wb') as f:\n",
    "        pickle.dump(mnist,f)\n",
    "    print(\"Save complete.\")\n",
    "\n",
    "def init():\n",
    "    download_mnist()\n",
    "    save_mnist()\n",
    "\n",
    "def load():\n",
    "    with open(\"mnist.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
    "\n",
    "class ThreeLayerNet(Net):\n",
    "\n",
    "    #Simple 3 layer NN\n",
    "\n",
    "    def __init__(self, N, D_in, H1, H2, D_out, weights=''):\n",
    "        self.FC1 = FC(D_in, H1)\n",
    "        self.ReLU1 = ReLU()\n",
    "        self.FC2 = FC(H1, H2)\n",
    "        self.ReLU2 = ReLU()\n",
    "        self.FC3 = FC(H2, D_out)\n",
    "\n",
    "        if weights == '':\n",
    "            pass\n",
    "        else:\n",
    "            with open(weights,'rb') as f:\n",
    "                params = pickle.load(f)\n",
    "                self.set_params(params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        h1 = self.FC1._forward(X)\n",
    "        a1 = self.ReLU1._forward(h1)\n",
    "        h2 = self.FC2._forward(a1)\n",
    "        a2 = self.ReLU2._forward(h2)\n",
    "        h3 = self.FC3._forward(a2)\n",
    "        return h3\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = self.FC3._backward(dout)\n",
    "        dout = self.ReLU2._backward(dout)\n",
    "        dout = self.FC2._backward(dout)\n",
    "        dout = self.ReLU1._backward(dout)\n",
    "        dout = self.FC1._backward(dout)\n",
    "\n",
    "    def get_params(self):\n",
    "        return [self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b]\n",
    "\n",
    "    def set_params(self, params):\n",
    "        [self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b] = params\n",
    "\n",
    "def MakeOneHot(Y, D_out):\n",
    "    N = Y.shape[0]\n",
    "    Z = np.zeros((N, D_out))\n",
    "    Z[np.arange(N), Y] = 1\n",
    "    return Z\n",
    "\n",
    "def draw_losses(losses):\n",
    "    t = np.arange(len(losses))\n",
    "    plt.plot(t, losses)\n",
    "    plt.show()\n",
    "\n",
    "def get_batch(X, Y, batch_size):\n",
    "    N = len(X)\n",
    "    i = random.randint(1, N-batch_size)\n",
    "    return X[i:i+batch_size], Y[i:i+batch_size]\n",
    "\n",
    "#mnist.init()\n",
    "X_train, Y_train, X_test, Y_test = load()\n",
    "X_train, X_test = X_train/float(255), X_test/float(255)\n",
    "X_train -= np.mean(X_train)\n",
    "X_test -= np.mean(X_test)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
    "\n",
    "print(X_train.shape)\n",
    "batch_size = 64\n",
    "D_in = 784\n",
    "D_out = 10\n",
    "\n",
    "print(\"batch_size: \" + str(batch_size) + \", D_in: \" + str(D_in) + \", D_out: \" + str(D_out))\n",
    "\n",
    "### TWO LAYER NET FORWARD TEST ###\n",
    "#H=400\n",
    "#model = nn.TwoLayerNet(batch_size, D_in, H, D_out)\n",
    "# H1=300\n",
    "# H2=100\n",
    "# model = ThreeLayerNet(batch_size, D_in, H1, H2, D_out)\n",
    "model = LeNet5()\n",
    "\n",
    "losses = []\n",
    "#optim = optimizer.SGD(model.get_params(), lr=0.0001, reg=0)\n",
    "optim = SGDMomentum(model.get_params(), lr=0.0001, momentum=0.80, reg=0.00003)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# TRAIN\n",
    "ITER = 25\n",
    "for i in trange(ITER):\n",
    "\t# get batch, make onehot\n",
    "\tX_batch, Y_batch = get_batch(X_train, Y_train, batch_size)\n",
    "\tY_batch = MakeOneHot(Y_batch, D_out)\n",
    "\n",
    "\t# forward, loss, backward, step\n",
    "\tY_pred = model.forward(X_batch)\n",
    "\tloss, dout = criterion.get(Y_pred, Y_batch)\n",
    "\tmodel.backward(dout)\n",
    "\toptim.step()\n",
    "\n",
    "\tif i % 10 == 0:\n",
    "\t\tprint(\"%s%% iter: %s, loss: %s\" % (100*i/ITER,i, loss))\n",
    "\tlosses.append(loss)\n",
    "\n",
    "\n",
    "draw_losses(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d78505-4723-4b3e-919f-629bc226e046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36c42977-4974-4a45-b0de-1a7067b642d9",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3acf8a91-2b12-45e1-a51b-742e0880fd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(Net):\n",
    "    # LeNet5\n",
    "\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv(3, 6, 5) # C1(1*32*32 --> 6*28*28)\n",
    "        self.ReLU1 = ReLU()\n",
    "        self.pool1 = MaxPool(2,2) # S2(6*28*28  --> 6*14*14)\n",
    "        self.conv2 = Conv(6, 16, 5) # C3(6*14*14 --> 16*10*10)\n",
    "        self.ReLU2 = ReLU()\n",
    "        self.pool2 = MaxPool(2,2) # S4(16*5*5)\n",
    "        self.FC1 = FC(16*5*5, 120) # C5()\n",
    "        self.ReLU3 = ReLU()\n",
    "        self.FC2 = FC(120, 84) # F6\n",
    "        self.ReLU4 = ReLU()\n",
    "        self.FC3 = FC(84, 50)\n",
    "        self.Softmax = Softmax()\n",
    "\n",
    "        self.p2_shape = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        h1 = self.conv1._forward(X)\n",
    "        a1 = self.ReLU1._forward(h1)\n",
    "        p1 = self.pool1._forward(a1)\n",
    "        h2 = self.conv2._forward(p1)\n",
    "        a2 = self.ReLU2._forward(h2)\n",
    "        p2 = self.pool2._forward(a2)\n",
    "        self.p2_shape = p2.shape\n",
    "        fl = p2.reshape(X.shape[0],-1) # Flatten\n",
    "        h3 = self.FC1._forward(fl)\n",
    "        a3 = self.ReLU3._forward(h3)\n",
    "        h4 = self.FC2._forward(a3)\n",
    "        a5 = self.ReLU4._forward(h4)\n",
    "        h5 = self.FC3._forward(a5)\n",
    "        a5 = self.Softmax._forward(h5)\n",
    "        return a5\n",
    "\n",
    "    def backward(self, dout):\n",
    "        #dout = self.Softmax._backward(dout)\n",
    "        dout = self.FC3._backward(dout)\n",
    "        dout = self.ReLU4._backward(dout)\n",
    "        dout = self.FC2._backward(dout)\n",
    "        dout = self.ReLU3._backward(dout)\n",
    "        dout = self.FC1._backward(dout)\n",
    "        dout = dout.reshape(self.p2_shape) # reshape\n",
    "        dout = self.pool2._backward(dout)\n",
    "        dout = self.ReLU2._backward(dout)\n",
    "        dout = self.conv2._backward(dout)\n",
    "        dout = self.pool1._backward(dout)\n",
    "        dout = self.ReLU1._backward(dout)\n",
    "        dout = self.conv1._backward(dout)\n",
    "\n",
    "    def get_params(self):\n",
    "        return [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b]\n",
    "\n",
    "    def set_params(self, params):\n",
    "        [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81673966-87c8-4de9-a24c-59eb6c579627",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63325/63325 [00:01<00:00, 41318.91it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 2907.88it/s]\n",
      "100%|██████████| 450/450 [00:00<00:00, 2984.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# 讀取圖片function\n",
    "def read_img_32(path) :\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "os.chdir('/home/rita/111/111-2DL/HW1')\n",
    "if __name__ == '__main__' : \n",
    "    with Pool(processes = 80) as p:\n",
    "        train_pic_32 = list(tqdm(p.imap(read_img_32, train_idx[::, 0], chunksize=100), total = train_idx.shape[0]))\n",
    "        val_pic_32 = list(tqdm(p.imap(read_img_32, val_idx[::, 0], chunksize=100), total = val_idx.shape[0]))\n",
    "        test_pic_32 = list(tqdm(p.imap(read_img_32, test_idx[::, 0], chunksize=100), total = test_idx.shape[0]))\n",
    "os.chdir('/home/rita/111/111-2DL/HW2')\n",
    "\n",
    "train_pic_32 = np.array(train_pic_32)\n",
    "val_pic_32 = np.array(val_pic_32)\n",
    "test_pic_32 = np.array(test_pic_32)\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = train_pic_32, train_y_onehot, test_pic_32, test_y_onehot\n",
    "X_val, Y_val = val_pic_32, val_y_onehot\n",
    "X_train, X_val, X_test = X_train/float(255), X_val/float(255), X_test/float(255)\n",
    "X_train -= np.mean(X_train)\n",
    "X_val -= np.mean(X_val)\n",
    "X_test -= np.mean(X_test)\n",
    "X_train = np.transpose(X_train, (0, 3, 1, 2))\n",
    "X_val = np.transpose(X_val, (0, 3, 1, 2))\n",
    "X_test = np.transpose(X_test, (0, 3, 1, 2))\n",
    "\n",
    "train_dataloader = Self_DataLoader(X_train, train_y_onehot, batch_size = 32, shuffle=True)\n",
    "val_dataloader = Self_DataLoader(X_val, val_y_onehot, batch_size = 32, shuffle=True)\n",
    "test_dataloader = Self_DataLoader(X_test, test_y_onehot, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bdbfbc-fd38-469d-9bfd-a0bdc636b6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [2:20:37<00:00, 17.08s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% Epoch: 1, loss: 3.81022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [2:18:47<00:00, 16.86s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0% Epoch: 2, loss: 3.79599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 494/494 [2:18:42<00:00, 16.85s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.0% Epoch: 3, loss: 3.81290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 408/494 [1:56:04<28:54, 20.17s/it]  "
     ]
    }
   ],
   "source": [
    "train_dataloader = Self_DataLoader(X_train, train_y, batch_size = 128, shuffle=True)\n",
    "# val_dataloader = Self_DataLoader(X_val, val_y, batch_size = 128, shuffle=True)\n",
    "# test_dataloader = Self_DataLoader(X_test, test_y, batch_size = 128)\n",
    "\n",
    "model = LeNet5()\n",
    "optim = SGD(model.get_params(), lr=0.0001, reg=0)\n",
    "criterion = CrossEntropyLoss()\n",
    "print('Start Training !')\n",
    "# TRAIN\n",
    "# 加 dataloader 版本\n",
    "n_epochs = 5\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "for i in range(n_epochs):\n",
    "    # train\n",
    "    temp_train_loss, temp_train_acc = 0, 0\n",
    "    with tqdm(total=train_dataloader.n_batches) as pbar:\n",
    "        for X_batch, Y_batch in train_dataloader :\n",
    "            Y_batch = self_onehot(Y_batch)\n",
    "            Y_pred = model.forward(X_batch)\n",
    "            loss, _ = criterion.get(Y_pred, Y_batch)\n",
    "            dout = Y_pred - Y_batch  # pred - label\n",
    "            model.backward(dout)\n",
    "            optim.step()\n",
    "            \n",
    "            pred_y = np.argmax(Y_pred, axis=1)\n",
    "            acc = np.mean(pred_y == np.argmax(Y_batch, axis=1))\n",
    "            \n",
    "            temp_train_loss += loss\n",
    "            temp_train_acc += acc\n",
    "             \n",
    "            pbar.update(1)\n",
    "    temp_train_loss /= train_dataloader.n_batches   \n",
    "    temp_train_acc /= train_dataloader.n_batches  \n",
    "    train_acc.append(temp_train_acc)\n",
    "    train_loss.append(temp_train_loss)\n",
    "    \n",
    "    print(\"%s%% Epoch: %s, loss: %.5f\" % (100*i/n_epochs, i + 1, loss))\n",
    "    \n",
    "    # validation\n",
    "    Y_pred = model.forward(X_val)\n",
    "    pred_y = np.argmax(Y_pred, axis=1)\n",
    "    acc = np.mean(pred_y == val_y)\n",
    "    # Y_batch = self_onehot(Y_val)\n",
    "    loss, dout = criterion.get(Y_pred, Y_val)\n",
    "    val_loss.append(loss)\n",
    "    val_acc.append(acc)\n",
    "\n",
    "    \n",
    "# save params\n",
    "weights = model.get_params()\n",
    "with open(\"./model/lenet5.pkl\",\"wb\") as f:\n",
    "    pickle.dump(weights, f)\n",
    "\n",
    "with open(\"./loss/train_loss.txt\", \"w\") as fp:\n",
    "    json.dump(train_loss, fp)\n",
    "with open(\"./acc/train_acc.txt\", \"w\") as fp:\n",
    "    json.dump(train_acc, fp)    \n",
    "with open(\"./loss/val_loss.txt\", \"w\") as fp:\n",
    "    json.dump(val_loss, fp)   \n",
    "with open(\"./acc/val_acc.txt\", \"w\") as fp:\n",
    "    json.dump(val_acc, fp)    \n",
    "    \n",
    "# draw\n",
    "plt.title('Loss')\n",
    "plt.plot(range(n_epochs), train_loss, label=\"train\")\n",
    "plt.plot(range(n_epochs), val_loss, label=\"val\", c = 'red')\n",
    "plt.legend()\n",
    "plt.savefig('./figure/lenet5_loss.png')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Accuracy')\n",
    "plt.plot(range(n_epochs), train_acc, label=\"train\")\n",
    "plt.plot(range(n_epochs), val_acc, label=\"val\", c = 'red')\n",
    "plt.legend()\n",
    "plt.savefig('./figure/lenet5_acc.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2725c-aaa2-4b48-968b-399aa371e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./loss/train_loss.txt\", \"r\") as fp:\n",
    "    train_loss = json.load(fp)\n",
    "with open(\"./acc/val_loss.txt\", \"r\") as fp:\n",
    "    val_loss = json.load(fp)\n",
    "with open(\"./loss/train_acc.txt\", \"r\") as fp:\n",
    "    train_acc = json.load(fp)\n",
    "with open(\"./acc/val_acc.txt\", \"r\") as fp:\n",
    "    val_acc = json.load(fp)\n",
    "    \n",
    "# draw\n",
    "plt.title('Loss')\n",
    "plt.plot(range(n_epochs), train_loss, label=\"train\")\n",
    "plt.plot(range(n_epochs), val_loss, label=\"val\", c = 'red')\n",
    "plt.legend()\n",
    "plt.savefig('./figure/lenet5_loss.png')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Accuracy')\n",
    "plt.plot(range(n_epochs), train_acc, label=\"train\")\n",
    "plt.plot(range(n_epochs), val_acc, label=\"val\", c = 'red')\n",
    "plt.legend()\n",
    "plt.savefig('./figure/lenet5_acc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589471da-6b38-4a1b-81d9-e922f386e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.forward(X_test)\n",
    "pred_y = np.argmax(Y_pred, axis=1)\n",
    "acc = np.mean(pred_y == test_y)\n",
    "print('Test Accuracy : ', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f08287b-d9c8-425c-84fa-c33600378961",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98042b8-2aef-4ed3-910f-52b6c183f16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de78e904-c7ba-4a5b-b9a2-f3fae38cb3fa",
   "metadata": {},
   "source": [
    "### Improved LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04533b14-b2dc-4da4-8566-b9532f84f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自己改的\n",
    "class Self_Sigmoid():\n",
    "    def __init__(self):\n",
    "        self.cache = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        self.cache = 1 / (1 + np.exp(-X))\n",
    "        return self.cache\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        SX = self.cache\n",
    "        dX = dout*SX*(1-SX)\n",
    "        return dX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce57445-d24d-4c8c-b268-3e1bede02550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Improved_LeNet5(Net):\n",
    "    # LeNet5\n",
    "\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv(3, 6, 3) # C1(3*32*32 --> 6*30*30)\n",
    "        self.ReLU1 = ReLU()\n",
    "        self.pool1 = MaxPool(2,2) # S2(6*30*30  --> 6*15*15)\n",
    "        self.conv2 = Conv(6, 16, 3) # C3(6*15*15 --> 16*13*13)\n",
    "        self.ReLU2 = ReLU()\n",
    "        # 16*13*13 --> 16*14*14\n",
    "        self.pool2 = MaxPool(2,2) # S4(16*14*14 --> 16*7*7)\n",
    "        # 16*7*7 -> 16*8*8\n",
    "        self.conv3 = Conv(16, 6, 3) # C3(16*8*8 --> 6*6*6)\n",
    "        self.ReLU3 = ReLU()\n",
    "        self.pool3 = MaxPool(2,2) # S4(6*6*6 --> 6*3*3)\n",
    "        \n",
    "        self.FC1 = FC(6*3*3, 120) # C5()\n",
    "        self.ReLU3 = ReLU()\n",
    "        self.FC2 = FC(120, 84) # F6\n",
    "        self.ReLU4 = ReLU()\n",
    "        self.FC3 = FC(84, 50)\n",
    "        self.Softmax = Softmax()\n",
    "\n",
    "        self.p3_shape = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        h1 = self.conv1._forward(X)\n",
    "        a1 = self.ReLU1._forward(h1)\n",
    "        p1 = self.pool1._forward(a1)\n",
    "        h2 = self.conv2._forward(p1)\n",
    "        a2 = self.ReLU2._forward(h2)\n",
    "        a2 = np.pad(a2, ((0, 0), (0, 1), (0, 1)), 'constant')\n",
    "        p2 = self.pool2._forward(a2)\n",
    "        p2 = np.pad(p2, ((0, 0), (0, 1), (0, 1)), 'constant')\n",
    "        \n",
    "        h3 = self.conv3._forward(p2)\n",
    "        a3 = self.ReLU3._forward(h3)\n",
    "        p3 = self.pool3._forward(a2)\n",
    "        \n",
    "        self.p3_shape = p3.shape\n",
    "        fl = p3.reshape(X.shape[0],-1) # Flatten\n",
    "        h3 = self.FC1._forward(fl)\n",
    "        a3 = self.ReLU3._forward(h3)\n",
    "        h4 = self.FC2._forward(a3)\n",
    "        a5 = self.ReLU4._forward(h4)\n",
    "        h5 = self.FC3._forward(a5)\n",
    "        a5 = self.Softmax._forward(h5)\n",
    "        return a5\n",
    "\n",
    "    def backward(self, dout):\n",
    "        #dout = self.Softmax._backward(dout)\n",
    "        dout = self.FC3._backward(dout)\n",
    "        dout = self.ReLU4._backward(dout)\n",
    "        dout = self.FC2._backward(dout)\n",
    "        dout = self.ReLU3._backward(dout)\n",
    "        dout = self.FC1._backward(dout)\n",
    "        dout = dout.reshape(self.p3_shape) # reshape\n",
    "        \n",
    "        dout = self.pool3._backward(dout)\n",
    "        dout = self.ReLU3._backward(dout)\n",
    "        dout = self.conv3._backward(dout)\n",
    "        \n",
    "        dout = self.pool2._backward(dout)\n",
    "        dout = self.ReLU2._backward(dout)\n",
    "        dout = self.conv2._backward(dout)\n",
    "        dout = self.pool1._backward(dout)\n",
    "        dout = self.ReLU1._backward(dout)\n",
    "        dout = self.conv1._backward(dout)\n",
    "\n",
    "    def get_params(self):\n",
    "        return [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b]\n",
    "\n",
    "    def set_params(self, params):\n",
    "        [self.conv1.W, self.conv1.b, self.conv2.W, self.conv2.b, self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b, self.FC3.W, self.FC3.b] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d0344a-56b5-4a3b-99bd-0a804dc1bee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterlab",
   "language": "python",
   "name": "jupyterlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
